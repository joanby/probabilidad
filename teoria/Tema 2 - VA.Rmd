---
title: "Tema 2 - Variables Aleatorias"
author: "Ricardo Alberich, Juan Gabriel Gomila y  Arnau Mir"
date: 
output: 
  ioslides_presentation:
    widescreen: true
    css: Mery_style.css
    logo: Images/matriz_mov.gif
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introducción a las variables aleatorias


## Introducción

* Hasta ahora nuestros sucesos han sido de varios tipos: $\{C,+\}$ en
la moneda, nombres de periódicos, ángulos en una ruleta, número de
veces que sale cara en el lanzamiento de una moneda etc\ldots.
* Necesitamos estandarizar de alguna manera todos estos sucesos. Una
solución es asignar a cada suceso un cierto conjunto de
números reales, es decir, convertir todos los sucesos en
*sucesos de números reales* para trabajar con ellos de forma
unificada.
* Para conseguirlo utilizaremos  unas funciones que
transformen los elementos del espacio muestral en números; esta funciones son las
variables aleatorias.


## Definición de variable aleatoria
 Comenzaremos dando una definición poco rigurosa, pero suficiente, de  variable aleatoria.

<div class="definition"> *Variable Aleatoria (definición práctica)* </div>


Una variable aleatoria (v.a.) es una aplicación que toma valores numéricos determinados por el resultado de un experimento aleatorio

<div class="observ">
**Notación**:
</div>
* Normalmente representaremos las v.a. por letras mayúsculas $X,Y,Z$\ldots
* Los valores que "*toman*" las v.a. los representaremos por letras minúsculas (las mismas en principio) $x,y,z\ldots$


## Ejemplo

<div class="example">
**Ejemplo**

Lanzamos un dado convencional de parchís el espacio muestral del experimento es

$$\Omega=\{1,2, 3, 4,  5, 6\}$$


</div>

<div class="example-sol">
Una v.a $X:\Omega\to\mathbb{R}$
sobre este espacio queda definida por 

$$\begin{equation*}
\begin{split}
X(1)&=1,X(2)=2,X(3)=3,\\
X(4)&=4,X(5)=5,X(6)=6.
\end{split}
\end{equation*}$$

* Ahora el suceso $A=\{2, 4, 6\}$, es decir "salir
número par", es equivalente a $\{X=2,X=4,X=6\}$.
* El suceso $B=\{1,2,3\}$, es decir "salir un número
inferior o igual a $3$" es  en términos de la v.a. $\{X=1,X=2,X=3\}$ o también $\{X\leq
3\}$.

</div>

## Ejemplo

<div class="example">
**Ejemplo**

Consideremos el experimento lanzar una anilla al cuello de una botella. Si acertamos a
ensartar la anilla en la botella el resultado del experimento es *éxito* y
*fracaso* en caso contrario. 
</div>

<div class="example-sol">
El espacio muestral asociado a este experimento será
$\Omega=\{\mbox{éxito, fracaso}\}$. Construyamos la siguiente variable aleatoria:

$$X:\{\mbox{éxito, fracaso}\}\to\mathbb{R}$$

definida por 

$$X(\mbox{éxito})=1 \mbox{ y } X(\mbox{fracaso})=0.$$

</div>


## Tipos de variables aleatorias
Hay dos tipos fundamentales de variables aleatorias, las discretas y las continuas.

Damos a continuación una definición informal.

<l class="definition">Variables Aleatórias Discretas y Continuas </l>

* Una variable aleatoria es **discreta** si sólo puede tomar una cantidad numerable de valores con probabilidad positiva.
* Las variables aleatorias **continuas**  toman  valores en intervalos.
* También existen las variables aleatorias **mixtas**; con una parte discreta y otra continua.



## Ejemplo

<div class="example">
**Ejemplo**

Son variables *aleatorias discretas*:
      
*  Número de artículos defectuosos en un cargamento.
*  Número de clientes que llegan a una ventanilla de un banco en una hora.
*  Número de errores detectados en las cuentas de una compañía.
*  Número de reclamaciones de una póliza de un seguro médico.
      
Son variables *aleatorias continuas*:
      
* Renta anual de una familia.
* Cantidad de petróleo importado por un país
* Variación del precio de las acciones de una compañía de telecomunicaciones.
* Porcentaje de impurezas en un lote de productos químicos.
      
</div>

# Variables aleatorias discretas

## Distribuciones de probabilidad para v.a. discretas.

* Pasamos ahora a describir el comportamiento  de la v.a. 
Para ello utilizaremos distintas
funciones que nos darán algunas probabilidades de la variable aleatoria.
* En el caso discreto estas funciones son la de probabilidad, y  la función de distribución o de probabilidad acumulada.
* En el caso discreto la función de probabilidad es la que nos da las probabilidades de los
sucesos elementales de la v.a. que definimos a continuación.



## Función de probabilidad para variables discretas


<l class="definition"> **Función de Probabilidad**</l>
La *función de probabilidad* (*probability mass function* o incluso abusando de notación *probability density function*)

de una variable aleatoria discreta $X$ a la que denotaremos por $P_{X}(x)$
está definida por

$$P_{X}(x)=P(X=x)$$

es decir la probabilidad de que $X$ tome el valor $x$.

Si $X$ no asume ese valor $x$, entonces
$P_{X}(x)=0$.
</div>

## Funcion probabilidad discretas

<l class="definition"> **Dominio de una variable aleatoria discreta** </l> 

El conjunto $$D_X=\{ x\in\mathbb{R} \mid P_X(x)>0\}$$ recibe el nombre de
*dominio* de la v.a. y son los valores posibles de esta variable. 

En el caso discreto lo más habitual es que $X(\Omega)=D_X$.



## Ejemplo

<div class="example">
**Ejemplo parchís**

Lanzamos un dado de parchís una vez, en esta ocasión representaremos los
sucesos elementales por el número de puntos de la cara obtenida, tenemos que
$$\Omega=\{\mbox{1-puntos,2-puntos,3-puntos,4-puntos,5-puntos,6-puntos}\}$$ 
y la variables aleatoria $X:\Omega\to \mathbb{R}$ viene definida por

$$X(\mbox{i-puntos})=i\mbox{ para } i=1,2,3,4,5,6.$$
</div>
  
<div class="example-sol ">

Supongamos que el dado está bien balanceado. Entonces
$$P_{X}(1)=P_{X}(2)=P_{X}(3)=P_{X}(4)=P_{X}(5)=P_{X}(6)=\frac16$$
Concretamente:
$$
P_{X}(x)=
  \left\{
  \begin{array}{ll}
   \frac16 & \mbox{si } x=1,2,3,4,5,6\\
  0 & \mbox{en otro caso }
  \end{array}
  \right.
$$
  
Su dominio es $$D_X=\{1,2,3,4,5,6\}.$$
</div>

## Ejemplo
<div class="example">
**Ejemplo lanzamiento moneda**


Sea $X$ la v.a. asociada al lanzamiento de una moneda. Su espacio muestral es  $\Omega=\{c,+\}$, la v.a. queda definida por:

$$X(\omega)=\left\{\begin{array}{ll} 1 & \mbox{si } \omega=c \\
0 & \mbox{si }\omega=+\end{array}\right.$$

</div>

<div class="example-sol">

Su función de probabilidad es:

$$P_{X}(x)=P(X=x)=\left\{\begin{array}{ll} \frac12 & \mbox{si } x=0,1\\
0 & \mbox{en otro caso}\end{array}\right.$$


Finalmente su dominio es $D_X=\{0,1\}.$

## Ejemplo 
<div class="example">
**Ejemplo urna con bolas**

Tenemos una urna con tres bolas rojas, una negra y dos blancas. Realizamos una extracción y observamos el color de la bola entonces un espacio muestral es
$$\Omega=\{roja, blanca, negra\}.$$ 
</div>

<div class="example-sol">

Una variable aleatoria asociada al experimento es:

$$X(\omega)=\left\{\begin{array}{ll} 1 & \mbox{si } \omega=roja  \\
2 & \mbox{si }\omega=negra \\ 3 & \mbox{si } \omega=blanca \end{array}\right.$$

## Ejemplo

<div class="example-sol">
La función de probabilidad es 

$$P_{X}(x)=\left\{\begin{array}{ll} \frac36 & \mbox{si } x=1\\
\frac16 & \mbox{si } x=2\\ \frac26 & \mbox{si } x=3\\ 0 & \mbox{en otro
caso}\end{array}\right.$$

El dominio de la v.a.  $X$ es $D_X=\{1,2,3\}.$

</div>

## Propiedades de la función de probabilidad.


<l class="prop"> Propiedades básicas de la función de porbabilidad </l>

Sea $X$ una v.a. discreta $X:\Omega:\to\mathbb{R}$ con dominio $D_X$. Su función de probabilidad $P_{X}$ verifica las siguientes propiedades:

* $0\leq P_{X}(x)\leq 1$ para todo $x\in\mathbb{R}$
* $\sum\limits_{x\in D_X} P_{X}(x)=1$


## Ejemplo

<div class="example">

**Ejemplo: Lanzamiento moneda** 

Lanzamos al aire tres veces, de forma independiente, una moneda perfecta. El espacio muestral de este experimento es
$$\Omega=\{ccc,cc+,c+c,+cc,c++,+c+,++c,+++\}$$ (expresados en orden de aparición).
</div>

<div class="example-sol">

Este espacio tiene todos los sucesos elementales
equiprobables. 

Consideremos la variable aleatoria asociada a este experimento:

$$X=\mbox{ número de caras en los tres lanzamientos}.$$ 

Su función de probabilidad es:

$$
\begin{array}{l}
P(X=0)=P(\{+++\})=\frac18\\ P(X=1)=P(\{c++,+c+,++c\})=\frac38\\
    P(X=2)=P(\{cc+,c+c,+cc\})=\frac38\\
    P(X=3)=P(\{ccc\})=\frac18
\end{array}
$$
</div>    
## Ejemplo
<div class="example-sol">

Podemos reescribir la función de probabilidad de $X$ de forma simplificada:
    
$$P_{X}(x)=\left\{\begin{array}{ll} \frac18 & \mbox{si } x=0, 3\\
\frac38 & \mbox{si } x=1,2\\ 0 & \mbox{en otro caso}\end{array}\right.$$



Efectivamente los valores de la función de distribución suman 1

$$\sum_{x=0}^3 P_X(x)= \frac18+\frac38+\frac38+\frac18=1.$$

</div>


## Función de distribución de variables aleatorias

<l class="definition"> **Distribución de Probabilidad**</l>

La función de *distribución de probabilidad* (acumulada) de la v.a. $X$ (de cualquier tipo;
discreta o continua) $F_{X}(x)$ representa la probabilidad de que $X$  tome un menor o igual que  $x$ es decir

$$F_{X}(x)=P(X\leq x)$$

Esta función también se denomina función de *distribución de
probabilidad o simplemente función de distribución* de una v.a., y en inglés
*cumulative distribution function* por lo que se abrevia con el acrónimo `cdf`.



## Propiedades


<l class="definition"> **Propiedades de la Función de Distribución**</l>

Sea $X$ una v.a. y $F_{X}$ su función
de distribución:

1. $P(X>x)=1-P(X\leq x)=1-F_{X}(x)$
2.  Sea a y b tales que $a<b$, $P(a<X\leq b)=P(X\leq b)-P(X\leq a)=F_{X}(b)-F_{X}(a)$



## Propiedades

<div class="dem"> 

**Demostración**:

Tenemos que el complementario de $X$ mayor que $x$ es:  $\overline{\left\{X>x\right\}}=\left\{X>x\right\}^c=\left\{X\leq x\right\}$. Además

$$P(X>x)=1-P(\overline{\left\{X>x\right\}})=1-P(X\leq x)=1-F_{X}(x)$$
    
lo que demuestra la primera propiedad

Por otro lado, que $X$ se encuentre entre dos valores $a$ y $b$ es $\left\{a< X \leq b\right\}= \left\{X\leq b\right\}-\left\{X\leq  a\right\}$

ahora podemos hacer 
    
$$
\begin{eqnarray*}
P(a<X\leq b)&=&P(\left\{X\leq b\right\}-\left\{X\leq a\right\})\\
&=& P(\left\{X\leq b\right\})-P(\left\{X\leq a\right\})\\
&=& F_{X}(b)-F_{X}(a).
\end{eqnarray*}
$$

</div>

## Propiedades

<l class="definition"> **Propiedades de la Función de Distribución**</l>

Sea $F_{X}$ la función de distribución  de una  v.a. $X$ entonces:
 
* $0\leq F_{X}(x)\leq 1$.
* La función $F_{X}$ es no decreciente.
* La función $F_{X}$ es continua por la derecha.
* Si denotamos por $F_X(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F(x)$,
entonces se cumple que $P(X< x_0)=F_X(x_0^{-})$ y que $P(X=x_0)=F_X(x_0)-F_X(x_0^{-})$.

## Propiedades

<l class="definition"> **Propiedades de la Función de Distribución**</l>

* Se cumple que $\displaystyle \lim_{x\to\infty} F_{X}(x)=1$; $\displaystyle \lim_{x\to-\infty}F_{X}(x)=0$.
*  Toda función $F$ verificando las propiedades anteriores es función de distribución de alguna v.a. $X$.
* $P(X>x)=1-F_{X}(x)$
* Dados $a,b\in \mathbb{R}$ con $a<b$ $$P(a<X\leq b)=F_{X}(b)-F_{X}(a).$$

## Advertencia desigualdades estrictas

En las propiedades anteriores no se pueden cambiar en general las desigualdades de
estrictas o no estrictas.

Veamos que propiedades tenemos cuando se cambian estas
desigualdades.


Dada una $F_{X}$ una función de distribución de la v.a. $X$ y denotamos por $$F_{X}(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F_{X}(x),$$,

entonces  se cumplen las siguientes igualdades...

## Advertencia desigualdades estrictas

<l class="prop">Propiedades </l>

* $P(X=x)=F_{X}(x)-F_{X}(x^{-})$
* $P(a< X< b)=F_{X}(b^{-})-F_{X}(a)$
* $P(a\leq X< b)=F_{X}(b^{-})-F_{X}(a^{-})$
* $P(X<a)=F_{X}(a^{-})$
* $P(a\leq X\leq b)=F_{X}(b)-F_{X}(a^{-})$
* $P(X\geq a)=1-F_{X}(a^{-})$
          
## Propiedades

<l class="prop">Más propiedades de la función de distribución </l> 

* Si  $F_X$ es continua en $x$ se tiene que $P(X=x)=0$.
Así que si la v.a. es continua $P(X\leq a)=P(X< a)+P(X=a)=P(X<a)$ y propiedades similares.
*  Sea $X$ una variable aleatoria discreta que con dominio $D_X$ y
que tiene por función de probabilidad $P_{X}(x)$ entonces su función de distribución
$F_{X}(x_0)$ es
$$F_{X}(x_0)=\sum_{x\leq x_0} P_{X}(x)$$

donde $\sum_{x\leq x_0}$ indica que sumamos todos los $x \in D_X$ tales que $x\leq
x_0$
  


## Propiedades

<div class="dem"> 

**Demostración**:


Si $X$ es continua $$P(X=a)=F(a)-F(a^{-})=F(a)-F(a)=0$$
por lo tanto 

$$P(X\leq a)=P(X<a)+P(X=a)= P(X<a)+0= P(X<a).$$


lo que demuestra la primera propiedad.

Para demostrar la segunda basta hacer


$$ 
F_{X}(x_0)= P(X\leq x_0)=P\left(\bigcup_{x\leq
x_0; x\in D_X} \{x\}\right)= \sum_{x\leq x_0}P(X=x)= \sum_{x\leq x_0}P_{X}(x).
$$
  
</div>


## Ejemplo

<div class="example">
**Ejemplo**

En el experimento del dado se tiene que:

$$P_{X}(x)=\left\{\begin{array}{ll} \frac16 & \mbox{si } x=1,2,3,4,5,6\\ 0 & \mbox{en el resto de casos}\end{array}\right.,$$

por lo tanto

   $$F_{X}(x)=P(X\leq x)=\left\{\begin{array}{ll}
   0 & \mbox{si } x<1\\
   \frac16 &\mbox{si } 1\leq x<2\\
   \frac26 &\mbox{si } 2\leq x<3\\
   \frac36 &\mbox{si } 3\leq x<4\\
   \frac46 &\mbox{si } 4\leq x<5\\
   \frac56 &\mbox{si } 5\leq x<6\\
   1 &\mbox{si } 6\leq x\end{array}\right.$$

</div>

## Ejemplo

<div class="example-sol">
Calculemos más detalladamente algún valor de $F_{X}$, por ejemplo:

$$
\begin{eqnarray*}
F_{X}(3.5) & = & P(X\leq 3.5)=  P(\{X=1\}\cup\{X=2\}\cup \{X=3\})\\
&=& P(\{X=1\})+P(\{X=2\})+P(\{X=3\})\\
&=& \frac16+\frac16+\frac16=\frac36 =\frac12,
\end{eqnarray*}
$$

o de otra forma

$$  
\begin{eqnarray*}
F_{X}(3.5)&=&\sum_{x\leq 3.5} P_X(x)=\sum_{x=1}^3 P(X=x)\\&=&\sum_{x=1}^3 \frac16= 3 \cdot
   \frac16=\frac12.
\end{eqnarray*}
$$

</div>


## Propiedades de la función de distribución

<l class="prop"> Propiedad</l>

Sea $X$ una variable con función de distribución $F_{X}$ entonces:
 
* $0\leq F_{X}(x)\leq 1$ para todo $x$
* Si $x<x'$ entonces $$F_{X}(x)\leq F_{X}(x').$$
Es una función creciente, no necesariamente estrictamente creciente.
* $\displaystyle \lim_{x\to -\infty}F_{X}(x)=0$ y $\displaystyle \lim_{x\to +\infty}F_{X}(x)=1$
* Es continua por la derecha $\displaystyle \lim_{x\to x_0^{+}}F_{X}(x)=F_{X}(x_0)$.
  



# Valores esperados  o esperanza


## Momentos de variables aleatorias discretas

* Al igual que en  la estadística descriptiva  se utilizan  distintas medidas para
resumir los valores centrales y para medir la dispersión de una muestra, podemos definir
las correspondiente medidas para variables aleatorias.

* A estas medidas se les suele añadir el adjetivo *poblacionales* mientras que a las que provienen de la muestra se las adjetiva como *muestrales*.


Por ejemplo  podemos buscar un valor que resuma toda la variable. Este valor es el que "*esperamos*" que se resuma la v.a. o esperamos que las realizaciones de la v.a. queden cerca de él. Veamos su definición formal.



## Esperanza  de un variable aleatoria discreta


<l class="definition">Esperanza de una variable aleatoria discreta </l>

El valor *esperado o esperanza* (*expected value* en inglés) $E(X)$ de una v.a. discreta $X$, se define como

$$
E(X)=\sum_{x\in X(\Omega)} x P_{X}(x)
$$


En ocasiones se le domina *media* (*mean* en inglés *mitjana* en catalán) poblacional o simplemente media y muy frecuentemente se la denota $\mu_{X}=E(X)$ o simplemente $\mu=E(X)$.


## Interpretación de la media aritmética para v.a. discretas

<div class="example">
**Ejemplo**

Supongamos que lanzamos un dado $n$ veces y obtenemos unas frecuencias absolutas $n_{i}$
para el resultado $i$ con $i=1,\ldots,6$. Sea $X$ la v.a. que nos representa el valor de
una tirada del dado.

Calculemos la media aritmética (o media muestral) de los datos

$$
\overline{x}=\frac{1\cdot n_1+2\cdot  n_2+3\cdot  n_3+4\cdot  n_4+5\cdot  n_5+6 \cdot 
n_6}{n}=\sum_{x=1}^6 x \frac{n_{x}}{n}.
$$

Si $n\to \infty$ se tiene que $\displaystyle\lim_{n\to \infty} \frac{n_{x}}{n}=P_{X}(x).$

Por lo tanto $E(X)=\displaystyle \lim_{n\to\infty}\sum_{x=1}^6x \frac{n_{x}}{n}.$

Entonces el valor esperado en una v.a. discreta puede entenderse como el valor promedio que
tomaría una v.a. en un número grande de repeticiones.

</div>



## Ejemplo

<div class="example">

**Ejemplo: Erratas en un texto**

Sea $X$= número  de erratas en una página de un texto con dominio $D_X=\{0,1,2\}$.

Resulta que

$$
P(X=0)=0.42, P(X=1)=0.4, P(X=2)=0.18.
$$
    
entonces
    
$$
E(X)=0\cdot 0.42+ 1\cdot 0.4 + 2 \cdot 0.18=0.76.
$$

Elegida una página del texto al azar esperamos encontrar $0.76$ errores por página.

Supongamos que en  el editor nos paga $2$ euros por cada página que
encontremos con $1$ error y $3$ euros por cada página con  dos errores (y nada por las
páginas correctas) ¿Cuánto esperamos cobrar si analizamos una página?

$$0\cdot 0.42 + 2\cdot 0.4 + 3\cdot 0.18=1.34$$
</div>


## Esperanzas de funciones de variables aleatorias discretas

<l class="definition"> **Esperanzas de funciones de variables aleatorias discretas** </l>

Sea $X$ una v.a. discreta con función de probabilidad $P_{X}$ y de distribución
$F_{X}$. Entonces el *valor esperado de una función* $g(x)$ es :

$$E(g(X))=\sum_{x}g(x) P_{X}(x).$$


## Propiedades de los valores esperados


<l class="prop"> Propiedades</l>
 
* $E(k)=k$ para cualquier constante $k$.
* Si $a\leq X\leq b$ entonces $a\leq E(X)\leq b$.
* Si $X$ es una v.a. discreta que toma valores enteros no negativos entonces
$E(X)=\sum_{x=0}^{+\infty}(1- F_X(x)).$
  
<div class="exercise">
**Ejercicio**

La demostración de las propiedades anteriores se deja como ejercicio.
</div>

## Ejemplo

<div class="example"> 
**Ejemplo: paleta de colores aleatoria**

Supongamos que estamos sentados delante de nuestro ordenador con un amigo y
le decimos que en dos minutos podemos programar una paleta  para poner colores a unos
gráficos. 

Queremos la que paleta tenga dos botones con las opciones color rojo y color azul.
Como hemos programado a gran velocidad resulta que el programa tiene un error; cada vez que
se abre la paleta los colores se colocan al azar (con igual probabilidad) en cada botón,
así que no sabemos en que color hemos de pinchar. 

Además, como nos sobraron $15$ segundos
para hacer el programa y pensando en la  comodidad del usuario, la paleta se cierra después de haber seleccionado  un
color y hay que volverla a abrir de nuevo.

La pregunta es ¿cuál es el valor esperado del
número de veces que hemos pinchar el botón de color azul antes de obtener este color?

</div>



## Ejemplo

<div class="example-sol"> 
Llamemos $X$ al número de veces que pinchamos en el botón azul (y nos sale rojo) hasta
obtener el primer azul. La variable $X$ toma valores en los enteros no negativos. Su
función de probabilidad queda determinada por

$$
P_X(x)=P(X=x)=P(\stackrel{x \mbox{veces}}{\overbrace{rojo, rojo,\ldots,rojo},azul})
=\left(\frac12\right)^{x+1}.
$$

</div>

## Propiedades de las series geométricas

<l class="prop">Series geométricas</l>

* Una *progresión geométrica* de razón $r$ es una sucesión de la  forma  
$$
r^0, r^1,\ldots,r^n,\ldots.
$$
* La serie geométrica es la suma de todos los
valores de la progresión geométrica $\displaystyle\sum_{k=0}^{+\infty} r^k$.
* Las sumas parciales desde el término $n_0$ al $n$ de una progresión geométrica valen 
$$
\sum_{k=n_0}^n r^k=\frac{r^{n_0}- r^n r}{1-r}.
$$
 
## Propiedades de las series geométricas

<l class="prop">Propiedades</l>

* Si $|r|<1$ la serie geométrica es convergente y $$\sum_{k=0}^{+\infty }
r^k=\frac1{1-r}$$. 
* En el caso en que se comience en $n_0$ se tiene que
$$\sum_{k=n_0}^{+\infty} r^k=\frac{r^{n_0}}{1-r}.$$

## Propiedades de las series geométricas

<l class="prop">Propiedades</l>


* Si $|r|<1$  también son convergentes las derivadas, respecto de $r$, de la serie geométrica y convergen a la derivada correspondiente. Así tenemos que
$$
\begin{eqnarray*}
\left(\sum_{k=0}^{+\infty} r^k\right)'= & \sum_{k=1}^{+\infty}k
r^{k-1} \left(\frac1{1-r}\right)'=\frac1{(1-r)^2}\\
\left(\sum_{k=0}^{+\infty} r^k\right)^{''}=& \sum_{k=2}^{+\infty}k (k-1)
r^{k-2}\left(\frac1{1-r}\right)^{''}=\frac2{(1-r)^3}
\end{eqnarray*}.
$$


## Ejemplo

<div class="example">

**Ejemplo (cont)**

Si seguimos con el ejemplo de la paleta de colores, su esperanza es:

$$
\begin{eqnarray*}
E(X)&=&\sum_{x=0}^{+\infty} x P(X=x)=\sum_{x=0}^{+\infty} x
\left(\frac12\right)^{x+1}\\
&= & \left(\frac12\right)^2\sum_{x=1}^{+\infty} x
\left(\frac12\right)^{x-1}=\left(\frac12\right)^2
\frac1{\left(1-\frac12\right)^2}=1.
\end{eqnarray*}
$$

Ahora calculemos su función de distribución

$$
\begin{eqnarray*}
F_X(x)&=& P(X\leq x)=\sum_{k=0}^x P(X=k)=\sum_{k=0}^x
\left(\frac12\right)^{k+1}\\
&=& \frac{\frac12-\frac12^{x+1}
\frac12}{1-\frac12}=1-\left(\frac12\right)^{x+1}
\end{eqnarray*}.
$$

</div>


## Ejemplo

<div class="example">

Como la variable toma valores enteros positivos, podemos calcular su valor esperado
de esta otra manera

$$E(X)=\sum_{x=0}^{+\infty} (1-F_X(x))=\sum_{x=0}^{+\infty}(\frac12)^{x+1}=\frac12
\frac1{1-\frac12}=1.$$

</div>

<div class="exercise">

**Ejercicio**

Calculad el valor esperado de la variable

$$
Y=\mbox{número de intentos para conseguir el color azul.}
$$
</div>




## Momentos de una variable aleatoria

<div class="definition"> Momentos de orden $m$</div>

Llamaremos  *momento de orden $m$* respecto al punto $C$ a 
$$E\left((X-C)^m\right)$$

* Cuando $C=0$ los momentos reciben el nombre de *momentos respecto al origen*.
* Cuando $C=E(X)$ reciben el nombre de *momentos centrales o respecto de la media*. Luego la esperanza es el momento de orden $1$ respecto al origen. Estos momentos son la versión poblacional de los momentos que vimos en el curso de estadística descriptiva, recibiendo estos último el nombre de momentos muestrales.


## Resumen conceptos

* Hemos descrito el comportamiento aleatorio de una v.a. discreta mediante sus funciones  de probabilidad $P_{X}$ y de distribución $F_{X}$.
* También tenemos un valor central; el valor esperado $E(X)$. 
* Como medida básica nos queda definir una medida de lo lejos que están los datos del valor central $E(X)$ una de estas medidas es la varianza de $X$.

# Medidas de la variabilidad


## Medidas de la variabilidad: la varianza


<div class="definition"> Varianza </div>

Sea $X$ una v.a. Llamaremos *varianza* de $X$ a

$$Var(X)=E((X-E(X))^2)$$

Por lo tanto la varianza es el momento central de orden $2$.

De forma frecuente se utiliza la notación $$\sigma_{X}^2=Var(X).$$
    
A la raíz cuadrada positiva de la varianza
$$\sigma_{X}=\sqrt{Var(X)}$$
   
se la denomina desviación típica  o estándar de $X$.




## Propiedades de la varianza
 
<l class="prop"> Propiedad </l>

* Si $X$ es una v.a. discreta con función de probabilidad $P_X$ su varianza es 
 $$\sigma_{X}^2=Var(X)=E((X-E(X))^2)=\sum_{x}(x-E(X))^2 P_{X}(x).$$
* Sea $X$ una v.a.
 $$Var(X)=E(X^2)-(E(X))^2=\sum_{x} x^2 P_{X}(X)-(E(X))^2$$
  


## Demostración

<div class="dem"> 

**Demostración de b)**
$$
\begin{eqnarray*}
Var(X)&= & \sum_{x}(x-E(X))^2 P_{X}(x) = \sum_{x}(x^2 -2 x E(X)+(E(X)^2) P_{X}(x)\\
&=& \sum_{x}x^2P_{X}(x) -  E(X)\sum_{x}2 x P_{X}(x) + (E(X)^2)\sum_{x} P_{X}(x)\\
&=& E(X^2)- 2 E(X) E(X) + (E(X))^2=E(X^2)-(E(X))^2.
\end{eqnarray*}
$$



</div>
## Ejemplo


<div class="example"> 
**Ejemplo**

Calculemos en  el ejemplo anterior la varianza del número de errores.
</div>

<div class="example-sol"> 

Recordemos que:
   
$$
P(X=0)=0.42,\quad P(X=1)=0.4, \quad P(X=2)=0.18
$$

y que

$$
E(X)=0.76
$$

Entonces:
    
$$
Var(X)=E(X^2)-(E(X))^2 = E(X^2)-(0.76)^2.
$$


</div>

## Ejemplo
<div class="example-sol">
  Ahora necesitamos calcular 
  
  $$E(X^2)= 0^2 (0.41)+ 1^2 (0.4)+ 2^2 (0.18)=0.4+0.72=1.12$$
  y por lo tanto
  
  $$Var(X)= E(X^2)-(0.76)^2=1.12-0.5776=0.542$$
  y $$\sqrt{Var(X)}=\sqrt{0.542}$$

  En resumen $\sigma_{X}^2=0.542$ y $\sigma_{X}=\sqrt{0.542}$
     

</div>

## Propiedades de la varianza
 
 
<l class="prop"> **Propiedades de la varianza**</l>

* $Var(X)\geq 0$
* $Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0$
* El mínimo de $E((X-C)^2)$ se alcanza cuando $C=E(X)$ y es $Var(X)$. Esta propiedad es una de las que hace útil a la varianza como medida de dispersión.
  

<div class="exercise">
**Ejercicio**

Se deja como ejercicio la demostración de estas propiedades.

</div>




# Esperanza y varianza de transformaciones lineales.


## Transformaciones lineales. 

<l class="definition"> Transformación lineal </l>

Un **cambio de variable lineal** o **transformación lineal** de una v.a. $X$ es otra v.a. $Y= a+ b X$  donde $a,b\in\mathbb{R}$.

<l class="prop"> Esperanza de una transformación lineal</l>

Sea $X$ una v.a. con $E(X)=\mu_{X}$ y $Var(X)=\sigma_{X}^2$ y $a,b\in\mathbb{R}$.
Entonces si $Y=a+b X$:
 
* $E(Y)=E(a + b X)=a+ b E(X)= a + b \mu_{X}$.
* $Var(Y)=Var(a+bX)=b^2 Var(X)= b^2 \sigma_{X}^2$
* $\sigma_{Y}=\sqrt{Var(Y)}=\sqrt{b^2 Var(X)}=|b| \sigma_{X}$
  
    
## Demostración

<div class="dem">
**Demostración**:

$$
\begin{eqnarray*}
E(Y)&=& E(a+bX)=\sum_{x}(a+b\cdot X)\cdot P_{X}(x)\\
&=& a \sum_{x} P_{X}(x) + b \sum_{x} x\cdot P_{X}(x)\\ 
&=& a + b\cdot E(X)=a + b \mu_{X}
\end{eqnarray*}
$$
</div>

<div class="exercise">
**Ejercicio**

Las demostración de las demás propiedades se dejan como ejercicio.
</div>

# Variables aleatorias continuas

## Variables aleatorias continuas definición.

* Como ya hemos dicho las variables aleatorias continuas toman valores en
intervalos o áreas.
* Lo más habitual es que estas variables tengan función de distribución continua y
derivable (salvo  a los más en una cantidad finita o numerable de puntos:-)).
* En lo que sigue supondremos que la función de distribución de variables
aleatorias continuas cumplen estas propiedades.
* Notemos que si $X$ es una v.a. con función de distribución continua se tiene que
$P(X=x_0)=F_X(x_0)-F(x_0^{-})=0$. Por lo que no tiene sentido definir *función de probabilidad*.



## Variables aleatorias continuas

* En general tendremos que $P(X<x_0)=P(X\leq x_0)$.
* Por otra parte podemos utilizar una regla parecida del
cociente entre casos favorables y casos posibles de Laplace  pero en
este caso el conteo se hace por la *medida*  de los casos
posibles partida por la *medida* de los casos favorables.
* Veamos un ejemplo de v.a. continua, que ampliaremos en el tema siguiente, en el que se utilizan todos estos conceptos.




## Ejemplo: Distribución uniforme en $[0,1]$.

<div class="example"> 

**Ejemplo: distancia el dardo centro** 

Supongamos que lanzamos un dardo a una diana de radio $1$, de forma que sea *equiprobable* cualquier distancia al centro (¡Cuidado! esto no es equivalente
a que cualquier punto de la diana  sea *equiprobable*).

Consideremos la v.a. continua $X=$ distancia al centro.
</div>

<div class="example-sol">

Su función de distribución es 

$$
F_{X}(x)=
\left\{
\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
x & \mbox{si } 0<x<1\\
1 & \mbox{si } x\geq 1
\end{array}
\right.
.
$$

Ya que

* C.F. *longitud favorable* es $x-0$.
* C.P. *longitud posible* es $1-0$.
* Luego 
$$P(X\leq x)=\frac{C.F.}{C.P.}=\frac{x-0}{1-0}=x$$


## Gráfica de la función de distribución uniforme

```{r figUNIF, fig.align='center',echo=FALSE}
curve(punif(x,0,1),xlim=c(-1,2),col="blue",
      main="Función de distribución de una v.a. uniforme en el intervalo unidad.")
```

## Propiedades

En las variables continuas los sucesos del tipo $\{X\leq x \}$ y $\{X< x \}$ tendrán la
misma probabilidad, y otros tipos de sucesos similares también, algunas de estas
propiedades se explicitan en la siguiente proposición.

<l class="prop">Propiedades</l>

Dada una v.a. continua $X$ se tiene que:
 
* $P(X\leq b)=P(X<b)$
* $P(X<b)=P(X<a)+P(a<X<b)$
* $P(a<X<b)=P(X<b)-P(X<a)$
  
## Demostración  
  
<div class="dem">
**Demostración:**

La primera es evidente  $P(X\leq b)=P(X<b)+P(X=b)=P(X<b)$

Para demostrar la segunda, tenemos

$$\{X<a\}\cap \{a<X<b\}=\emptyset$$ 
$$\{X<a\}\cup \{a<X<b\}=\{X<b\}$$ 

entonces

$$
\begin{eqnarray*}
P(X\leq b)= & P(\{X<a\}\cup \{a<X<b\})\\
& = P(X<a)+P(a<X<b)
\end{eqnarray*}
$$


</div>

<div class="exercise">
**Ejercicio**

La demostración de la tercera propiedad es similar a la segunda pero aplicando la primera. Queda de ejercicio.
</div>


## Propiedades de la función de distribución

Las propiedades anteriores  y combinaciones de ellas se pueden
escribir utilizando la función de distribución de $X$:


<l class="prop"> Propiedades de la Función de Distribución </l>

Dada una variable aleatoria continua se tiene que:

* $F_{X}(b)=F_{X}(a)+P(a<X<b)$
* $P(a<X<b)=F_{X}(b)-F_{X}(a)$
* $P(a\leq X\leq b)=F_{X}(b)-F_{X}(a)$



<div class="exercise"> 

**Ejercicio**

Se deja la demostración como ejercicio 
</div>


## Ejemplo 

<div class="example"> **Ejemplo: lanzamiento de dardos**


En los dardos:
$$P(0.25<X<0.3)=F_{X}(0.3)-F_{X}(0.25)=$$
$$=0.3-0.25=0.05$$
</div>

## Función de densidad

<l class="definition"> **Función de densidad** </l> 

Una función $f:\mathbb{R}\to\mathbb{R}$ es una función de densidad sobre $\mathbb{R}$ si cumple que


* $f_{X}(x)\geq 0$ para todo $x \in\mathbb{R}.$
* $f$ es continua salvo a lo más en una cantidad finita de puntos sobre
cada intervalo acotado de $\mathbb{R}$.
* $\displaystyle\int\limits_{-\infty}^{+\infty} f_{X}(x) dx=1.$

## Función de densidad de una variable aleatoria.

<l class="definition"> **Función de densidad de una variable aleatoria** </l>

Sea $X$ una v.a. con función de distribución $F_X$. Sea $f:\mathbb{R}\to\mathbb{R}$ una función de densidad tal que

$$F_X(x)=\displaystyle\int_{-\infty}^{x} f_X(t) dt.\mbox{ para todo } x\in\mathbb{R}.$$

Entonces $X$ es una variable aleatoria continua y $f_X$ es la densidad de la v.a.  $X$.


##  Dominio de una variable aleatoria continua

El conjunto $D_X=\{x\in\mathbb{R}| f_x(x)>0\}$ recibe el nombre de <l class="definition"> soporte o dominio de la
variable aleatoria continua</l> y se interpreta su conjunto de resultados posibles.


<div class="example">
**Ejemplo**

En nuestra diana, la función $f$ es una densidad

$$
f_{X}(x)=\left\{
\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
1 & \mbox{si } 0 < x < 1\\
0 & \mbox{si } 1\leq x
\end{array}\right.
$$

que es la densidad de $X$, en efecto:

</div>

## Densidad diana

<div class="example-sol">

$$
f_{X}(x)=\left\{
\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
1 & \mbox{si } 0 < x < 1\\
0 & \mbox{si } 1\leq x
\end{array}\right.
$$

Si $x \leq 0$ entonces $\displaystyle\int_{-\infty}^x f_X(t) dt = 0.$

Si $0\leq x\leq 1$ entonces $\displaystyle\int_{-\infty}^x f_X(t) dt = \int_0^x 1 dt = x.$

Si $x\geq 1$  entonces $\displaystyle\int_{-\infty}^x f_X(t) dt = \int_0^1 1 dt = 1.$


Por lo tanto  $F_X(x)=\displaystyle\int_{-\infty}^x f_X(t) dt$ para todo $x\in\mathbb{R}.$

</div>

##  Densidad diana


<div class="example-sol">


```{r fig.align="center",  fig_caption="Función de densidad de una v.a. uniforme en el intervalo$(0,1)$"}
curve(dunif(x,0,1),xlim=c(-0.5,1.5),col="blue",
      main="Densidad de la distribución uniforme en [0,1]")
```
</div>

## Utilidad de la función de densidad

La función de densidad nos permite calcular diversas probabilidades.

<l class="prop">Propiedades de la función de densidad </l> 

Sea $X$ una v.a. continua con función de distribución $F_X$ y de
densidad $f_X$, entonces
 
* $$\begin{eqnarray*}
P(a< X< b) &=&  P(a<X\leq b)= P(a\leq X< b)=\\
 & & P(a\leq X\leq b)= \displaystyle\int_{a}^b f_X(x) dx.
\end{eqnarray*}
$$
* Si $A$ es un conjunto  adecuado de $\mathbb{R}$ entonces 
$$P(X\in A)=\displaystyle\int_{A} f(x) dx=\displaystyle\int_{A\cap D_X} f(x) dx.
$$




## Utilidad de la función de densidad

<l class="prop">Propiedades de la función de densidad </l> 

Sea $X$ una v.a. continua con función de distribución $F_X$ y de densidad $f_X$, entonces:

* Si $f_x$ es continua en un punto $x$, $F_X$ es derivable en ese punto y
$F_X'(x)=f_X(x).$
* $P(X=x)=0$ para todo $x\in\mathbb{R}.$
  

<div  class="exercise"> **Ejercicio**

Comprobar estas propiedades en el ejemplo de la diana. </div>




## Ejemplo tiempo ejecución de un proceso

<div  class="example">
**Ejemplo: Tiempo ejecución de un proceso.**

Sea $X=$ tiempo de ejecución de un proceso. Se supone que $X$ sigue una distribución uniforme en dos unidades de tiempo, si tarda más el proceso se cancela.

Calculemos la función de densidad y de distribución de la v.a $X$.

</div>

<div  class="example-sol">

Entonces

$$
F_{X}(x)=P(X\leq x)=\frac{CF}{CP}=\frac{x}2
$$


Luego su función de distribución es:

$$
F_{X}(x)=\left\{\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
\frac{x}2 & \mbox{si } 0<x<2\\
1 & \mbox{si } 2\leq x
\end{array}\right.
$$

## Ejemplo tiempo ejecución de un proceso


Su función de densidad por su lado es:
$$
f_{X}(x)=F_{X}'(x)=\left\{\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
\frac12 & \mbox{si } 0<x\leq 2\\
0 & \mbox{si } 2\leq x
\end{array}\right.
$$

Efectivamente

* $f_{X}(x)\geq 0,$ y tiene un conjunto finito de discontinuidades.
* $F_X(x)=\int_{-\infty}^x f_X(t) dt.$ para todo $x\in \mathbb{R}$ <l class="exercise">(Ejercicio,
resolverlo gráficamente.)</l>
* $\int\limits_{-\infty}^{+\infty}f_{X}(x)dx=
\int\limits_0^2\frac12dx=\frac{x}2\mid_0^2=
=\frac22-\frac02=1.$

</div>

## Ejemplo tiempo ejecución de un proceso

<div  class="exercise">
**Ejercicio: Tiempo de un proceso:**

Calcular la probabilidad de que uno de nuestros procesos tarde
más de una unidad de tiempo en ser procesado. Calcular también la  probabilidad de
que dure entre $0.5$ y $1.5$ unidades de tiempo.
</div>

# Esperanza y varianza para variables aleatorias continuas

## Esperanza y varianza para variables aleatorias continuas

Los mismos comentarios y definiciones que se dieron en la sección correspondiente del tema
de estadística descriptiva son aplicables aquí.

Así que sólo daremos las definiciones, la forma de cálculo y algunos ejemplos.

En lo que sigue, salvo que diagamos lo contrario,  $X$  es una v.a. continua con función de densidad $f_{X}(x)$



## Esperanza y varianza para variables aleatorias continuas

<l class="definition"> Esperanza v.a. continuas </l>

* Su esperanza es:
$$E(X)=\displaystyle\int\limits_{-\infty}^{+\infty} xf_{X}(x)dx.$$
* Si $g(x)$ es una función de la variable $X$ entonces:
$$E(g(X))=\displaystyle\int\limits_{-\infty}^{+\infty} g(x)\cdot f_{X}(x)dx.$$

## Esperanza y varianza para variables aleatorias continuas

<l class="definition"> Varianza v.a. continuas </l>


* Su varianza es:
$$
Var(X)=\sigma_{X}^2=E((X-\mu_{X})^2)=
\displaystyle\int\limits_{-\infty}^{+\infty} (x-\mu_{X})^2 f_{X}(x)dx.
$$
* Su desviación típica es:  $$\sigma_{X}=+\sqrt{\sigma_{X}^2}.$$


## Propiedades

<l class="prop"> Propiedades </l>

* $\sigma_{X}^2\geq 0$
* $Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0$
* $Var(x)=E(X^2)-\mu_{X}^2=\int\limits_{-\infty}^{+\infty}x^2 f_{X}(x)dx - \mu_{X}^2.$
* El mínimo de $E((X-C)^2)$ se alcanza cuando $C=E(X)$ y es $Var(X)$.



## Ejemplo

<div  class="example">

**Ejemplo: Dardo**

Calcular $\mu_{X}$ y $\sigma_{X}^2$ en el dardo.
</div>

<div  class="example-sol">
Resultado 
$$\mu_{X}=\frac12,$$ 
$$E(X^2)=\frac13,$$
$$Var(X)=\frac1{12}.$$

</div>


## Esperanza de trasformaciones lineales de v.a. continuas

<l class="prop"> Proposición</l>

Sea $X$ una v.a. continua con $E(X)=\mu_{X}$ y $Var(X)=\sigma_{X}^2$ sea $Y=a+b X$, donde
$a,b\in\mathbb{R}$, es una nueva v.a. continua obtenida mediante una transformación lineal de $X$.
Se verifican las mismas propiedades que en el caso discreto:

* $E(Y)=E(a+b X)=a+b E(X)$
* $Var(Y)=Var(a+b X)=b^2 Var(X)$
* $\sigma_{Y}=|b| \sigma_{X}$
* $Z=\frac{X-\mu_{X}}{\sigma_{X}}$ es una transformación
lineal de $X$ de forma que
$$E(Z)=0 \mbox{ y } Var(Z)=1$$





## Ejemplo

<div class="example"> 
**Ejemplo**

En una empresa de venta de vinos por internet, sea
$X=$ número de  litros de vino del país vendidos en un año.
Supongamos que sabemos que $E(X)=10000$ y que $Var(X)=100$
Supongamos que los gastos fijos de distribución son
50.000 &euro; y el beneficio por litro es de 10 &euro; por botella.
Definimos $T=10 X-50000$ que será el beneficio después de gastos.
</div>

<div class="example-sol"> 

Entonces la esperanza del beneficio es 
$$E(T)=10 E(X)-50000 = 50000$$
y
$$Var(T)=10^2 Var(X)= 10000$$
</div>

# Transformaciones de variables aleatorias


## Transformaciones de variables aleatorias

Muchas variables aleatorias son funciones de otras v.a. En lo que sigue resumiremos diversas técnicas para dada una v.a. $X$ y una
transformación $Y=h(X)$  encontrar $F_{Y}$ a
partir de $F_{X}$.


## Propiedad

<l class="prop">Tranformación de v.a. discretas </l>

Sea $X$ una v.a. discreta con $X(\Omega)=\{x_1,x_2,\ldots,x_{n},..\}$ y sea $h:\mathbb{R}\to\mathbb{R}$ una aplicación.
Entonces $Y=h(X)$ es también una v.a. discreta. Además si $P_X$
y $F_{X}$ son las funciones de probabilidad y de distribución de
$X$ entonces

 
* $\displaystyle P_{Y}(y)=\sum_{x_{i}|h(x_{i})=y}P_X(x_{i}).$
* $\displaystyle F_{Y}(y)=\sum_{x_{i}|h(x_{i})\leq y} P_X(x_{i}).$

## Propiedades

Desafortunadamente para variables no discetas el asunto  no es tan sencillo como el anterior, pues la transformación de, por ejemplo, una v.a. continua puede ser continua, discreta, mixta...

<l class="prop">Transformación de v.a. continuas en continuas</l>

Sea $X$ una v.a. continua cuya función de densidad es $f_{X}$. Sea
$h:\mathbb{R}\to\mathbb{R}$ una aplicación estrictamente monótona y derivable, tal
que $h'(x)\not=0$ para todo $x\in\mathbb{R}$. Sea $Y=h(X)$ la
transformación de $X$ por $h$. Entonces $Y$ es una v.a. continua con función
de densidad

$$f_{Y}(y)=\left.\frac{f_{X}(x)}
{\left|h'(x)\right|}\right|_{x=h^{-1}(y)}$$



## Propiedades


<l class="prop"> Densidad de una transformación de una v.a. continua</l>

Sea $X$ una v.a. continua cuya función de densidad es $f_{X}$.  Sea 
$$h:\mathbb{R}\to\mathbb{R}$$ 
una aplicación, no necesariamente monótona tal que :

* sea derivable con derivada no nula
* la ecuación $h(x)=y$ tiene un número finito de soluciones
$x_1,x_2,..,x_{n}$

entonces:

$$
\displaystyle f_{Y}(y)=\left.\sum_{k=1}^{n} \frac{f_{X}(x)}
{\left|h'(x)\right|}\right|_{x=x_{k}}.
$$


## Método general del transformación de v.a.

Cuando no podamos aplicar las propiedades anteriores intentaremos
calcular primero la función de distribución de la transformación
y luego su densidad.

Notemos que en general si $Y=g(X)$ es una v.a. transformación  de la
v.a. $X$ entonces

$$
F_{Y}(y)=P(Y\leq y)=P(g(X)\leq y).
$$

## Método general del transformación de variables aleatorias


Por ejemplo si $g$ es estrictamente creciente y cont.

$$
F_{Y}(y)=P(g(X)\leq y)=P(X\leq g^{-1}(y))=F_{X}(g^{-1}(y)).
$$

y si $g$ es estrictamente decreciente y cont.
$$
F_{Y}(y)=P(g(X)\leq y)=P(X\geq g^{-1}(y))=1-F_{X}(g^{-1}(y)).
$$



# Desigualdades   básicas: Markov y Chebychev



## Desigualdades de Markov y de Chebychev

* En esta sección distintas desigualdades que acotan determinadas probabilidades de
una variable aleatoria.
* Estas desigualdades sirven en algunos casos para acotar probabilidades de determinados sucesos.
* También son útiles desde el punto de vista teórico, por ejemplo para justificar que la varianza es una mediada de la dispersión de
los datos.




## Desigualdad de Markov

<l class="prop"> Desigualdad de Markov</l>

Sea $X$ una v.a. positiva con $E(X)$ finita. Entonces 

$$P(X\geq a)\leq \frac{E(X)}{a}\mbox{ para todo }a>0.$$

<div class="dem">
**Demostración**:

Si $X$ es continua  y solo toma valores positivos

$$
\begin{eqnarray*}
E(X) &=& \int_{-\infty}^{+\infty} x f_{X}(x) dx=  \int_0^{+\infty} x f_{X}(x) dx=  \int_0^{a} x f_{X}(x) dx +\int_{a}^{+\infty} x f_{X}(x) dx \\
& &\geq   \int_{a}^{+\infty} x
f_{X}(x) dx \geq a \int_{a}^{+\infty}
f_{X}(x) dx = a \cdot  P(X\geq a)
\end{eqnarray*}.
$$

de donde se sigue que 

$$P(X\geq a)\leq \frac{E(X)}{a}.$$

</div> 

## Desigualdad  de Markov

<l class="prop"> Corolario</l>

Sea $X$ una v.a. con $E(X)$ finita entonces  para todo $a>0$

$$P(|X|\geq a )\leq \frac{E(|X|)}{a}.$$
<div class="exercise">
**Ejercicio**

Demuestra el corolario anterior a partir de la desigualdad de Markov.
</div>

## Desigualdad de Chebychev


La desigualdad de Chebychev también se denomina  de Chebyshov y en inglés Chebyshev.

<l class="prop"> Desigualdad de Chebychev</l>

Sea  $X$ una v.a.con $E(X)=\mu$ y $Var(X)=\sigma^2$  entonces para todo $a>0$

$$P(|X-\mu|\geq a)\leq \frac{\sigma^2}{a^2}$$ 

## Demostración desigualdad de Chebychev

<div class="dem"> **Demostración**

Apliquemos la consecuencia de la desigualdad de Markov a la v.a.
no negativa 

$$Y^2=(X-\mu)^2$$

entonces

$$
P(Y^2\geq a^2) \leq 
\frac{E(Y^2)}{a^2}=\frac{E((X-\mu)^2)}{a^2}
= \frac{Var(X)}{a^2}=\frac{\sigma^2}{a^2}
.
$$




Por otra parte

$$
P(Y^2\geq a^2)=P(|Y|\geq a)= P(|X-\mu|\geq a).
$$

hecho que, junto con la desigualdad anterior,
demuestra el resultado.

</div>


## Uso de la desigualdad de Chebychev

<div class="observ"> **Utilidad básica de la desigualdad de Chebychev**</div>

Supongamos que $X$ es una v.a. con $Var(X)=0$
entonces.


Aplicando la desigualdad anterior

$$P(|X-E(X)|\geq a )=0\mbox{ para todo }a>0$$ 
lo que implica que

$$P(X=E(X))=1.$$

Por lo que  probabilidad de que $X$ sea
constantemente $E(X)$ es 1.

Lo que nos confirma la utilidad de la varianza es una
medida de la dispersión de los datos.



## Ejemplo

<div class="example">
**Ejemplo**

Se sabe que el tiempo de respuesta medio y la desviación típica de un sistema multiusuario  son 15 y 3 u.t.respectivamente. Entonces:

$$
P(|X-15|\geq 5)\leq \frac9{25}=0.36.
$$

</div>

Si substituimos $a$ por $a\cdot \sigma$ en la
desigualdad de Chebychev, nos queda:

$$
P(|X-\mu|\geq a \sigma)\leq
\frac{\sigma^2}{(a\sigma)^2}=\frac1{a^2}.
$$

Que es otra manera de expresar la desigualdad de Chebychev.


## Más formas de la desgualdad de Chebychev

La desigualdad de Chebychev también se puede escribir de al menos dos maneras más:

$$
P(\mu-a\leq X\leq \mu+a)\geq 1-\frac{\sigma^2}{a^2}
$$


y tomado como $a=k\cdot \sigma$

$$
P(\mu-k\cdot \sigma\leq X\leq \mu+ k \cdot \sigma)\geq 1-\frac1{k^2}
$$


## La varianza como medida de dispersión

Tomando la segunda expresión que hemos visto para la desigualdad de
Chebychev para distintos valores de $k>0$ tenemos la siguiente tabla.

<center>
| k | $P(|X-E(X)|\geq k  \cdot \sigma)$|
|---|---|
| 1 | $\leq 1$ |
| 2 | $\leq 0.25$ |
| 3 | $\leq 0.111$ |
| 4 | $\leq 0.0025$ |
</center>

## Interpretación de la desigualdad

* Por ejemplo para $k=2$ esta desigualdad se puede interpretar como que dada una v.a. $X$ con cualquier distribución que tenga $E(X)$ y $Var(X)$ finitos *la  probabilidad de que un valor se aleje de la media $\mu$ más de $a=2$ desviaciones típicas es menor o igual que $0.25$*.

* Es decir sólo el 25\% de los valores estarán alejados de la media
más de $2\sigma$

¡*Sea cual sea la distribución de la v.a.*!




